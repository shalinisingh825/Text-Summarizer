{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b39f6f1-6e36-448b-85f5-ea326f3f68b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "           AI-Powered Text Summarizer\n",
      "============================================================\n",
      "\n",
      "This app summarizes text into 3 key sentences.\n",
      "You can either:\n",
      "1. Enter text directly\n",
      "2. Provide a URL to a news article or blog post\n",
      "3. Use the sample text provided\n",
      "\n",
      "----------------------------------------\n",
      "Choose an option:\n",
      "1. Enter text manually\n",
      "2. Enter URL\n",
      "3. Use sample text\n",
      "4. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text (press Enter twice to finish):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Solve my assignment in python with all detailed analysis  Data Science Assignment Instructions â€“ Web3 Trading Team ðŸ“‚ Standardized Submission Format All candidate submissions must strictly follow this structure. Non-compliance will result in rejection of the application. ðŸ”¹ Create a root directory with the following format: ds_<candidate_name> ðŸ”¹ Inside this directory, maintain the following structure: ds_<candidate_name>/ â”œâ”€â”€ notebook_1.ipynb # All work should be done in Google Colab notebooks. â”œâ”€â”€ notebook_2.ipynb # (Optional) Additional Colab notebook if needed. â”œâ”€â”€ csv_files/ # Store all CSVs or data outputs here. â”‚ â””â”€â”€ *.csv # Any intermediate or processed data files. â”œâ”€â”€ outputs/ # Store all visual outputs, graphs, or charts here. â”‚ â””â”€â”€ *.png / *.jpg # Image results of EDA, charts, etc. â”œâ”€â”€ ds_report.pdf # Final summarized insights and explanations. â””â”€â”€ README.md # (Optional but encouraged) Setup instructions, notes. ðŸ”¹ All code must be shared as Google Colab links with access set to 'Anyone with the link can  view'. ðŸ”¹ The exact same structure must be updated in the GitHub repository as well. ðŸ”¹ Failing to comply with any of the above instructions will result in immediate rejection. ðŸ“‚ Assignment Overview You are expected to explore and analyze the relationship between trader behavior and market sentiment using two key datasets. ðŸ“‚ Datasets 1. Bitcoin Market Sentiment Dataset  - Columns: Date, Classification (Fear / Greed) 2. Historical Trader Data from Hyperliquid  - Columns include: account, symbol, execution price, size, side, time, start position, event, closedPnL, leverage, etc. ðŸ“‚ Objective Analyze how trading behavior (profitability, risk, volume, leverage) aligns or diverges from overall market sentiment (fear vs greed). Identify hidden trends or signals that could influence smarter trading strategies. ðŸ“‚ Dataset attached for your refrence  Solve my assignment in python with all detailed analysis  and give me the code that i can submit\n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "SUMMARY:\n",
      "========================================\n",
      "Solve my assignment in python with all detailed analysis  Data Science Assignment Instructions â€“ Web3 Trading Team ðŸ“‚ Standardized Submission Format All candidate submissions must strictly follow this structure. â”œâ”€â”€ csv_files/ # Store all CSVs or data outputs here. ðŸ“‚ Datasets 1.\n",
      "\n",
      "----------------------------------------\n",
      "Choose an option:\n",
      "1. Enter text manually\n",
      "2. Enter URL\n",
      "3. Use sample text\n",
      "4. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-4):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using the Text Summarizer!\n"
     ]
    }
   ],
   "source": [
    "# text_summarizer.py\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class TextSummarizer:\n",
    "    def __init__(self):\n",
    "        # Download required NLTK data\n",
    "        try:\n",
    "            nltk.data.find('tokenizers/punkt')\n",
    "        except LookupError:\n",
    "            nltk.download('punkt')\n",
    "        \n",
    "        try:\n",
    "            nltk.data.find('corpora/stopwords')\n",
    "        except LookupError:\n",
    "            nltk.download('stopwords')\n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.punctuation = set(string.punctuation)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess the input text\"\"\"\n",
    "        # Convert to lowercase and tokenize sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        return sentences\n",
    "    \n",
    "    def score_sentences(self, sentences):\n",
    "        \"\"\"Score sentences based on word frequency\"\"\"\n",
    "        # Create word frequency dictionary\n",
    "        word_freq = defaultdict(int)\n",
    "        \n",
    "        # Count word frequencies (excluding stop words and punctuation)\n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence.lower())\n",
    "            for word in words:\n",
    "                if word not in self.stop_words and word not in self.punctuation:\n",
    "                    word_freq[word] += 1\n",
    "        \n",
    "        # Score each sentence based on word frequencies\n",
    "        sentence_scores = {}\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            words = word_tokenize(sentence.lower())\n",
    "            score = 0\n",
    "            for word in words:\n",
    "                if word in word_freq:\n",
    "                    score += word_freq[word]\n",
    "            sentence_scores[i] = score / len(words) if words else 0  # Normalize by length\n",
    "        \n",
    "        return sentence_scores\n",
    "    \n",
    "    def summarize(self, text, num_sentences=3):\n",
    "        \"\"\"\n",
    "        Summarize the input text into specified number of sentences\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to summarize\n",
    "            num_sentences (int): Number of sentences for summary (default: 3)\n",
    "        \n",
    "        Returns:\n",
    "            str: Summarized text\n",
    "        \"\"\"\n",
    "        if not text.strip():\n",
    "            return \"Please provide some text to summarize.\"\n",
    "        \n",
    "        # Preprocess text\n",
    "        sentences = self.preprocess_text(text)\n",
    "        \n",
    "        if len(sentences) <= num_sentences:\n",
    "            return \"Text is already short enough. Original text:\\n\" + text\n",
    "        \n",
    "        # Score sentences\n",
    "        sentence_scores = self.score_sentences(sentences)\n",
    "        \n",
    "        # Select top N sentences\n",
    "        ranked_sentences = sorted(sentence_scores.items(), \n",
    "                                key=lambda x: x[1], reverse=True)[:num_sentences]\n",
    "        \n",
    "        # Sort selected sentences by their original order\n",
    "        summary_sentences = sorted([sentences[idx] for idx, score in ranked_sentences],\n",
    "                                 key=lambda x: sentences.index(x))\n",
    "        \n",
    "        # Join sentences to form summary\n",
    "        summary = ' '.join(summary_sentences)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def summarize_from_url(self, url):\n",
    "        \"\"\"Extract text from URL and summarize it\"\"\"\n",
    "        try:\n",
    "            # Fetch webpage content\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse HTML content\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Extract text from paragraphs\n",
    "            paragraphs = soup.find_all('p')\n",
    "            text = ' '.join([p.get_text() for p in paragraphs])\n",
    "            \n",
    "            if not text.strip():\n",
    "                return \"Could not extract meaningful text from the URL.\"\n",
    "            \n",
    "            return self.summarize(text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error processing URL: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the text summarizer\"\"\"\n",
    "    summarizer = TextSummarizer()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"           AI-Powered Text Summarizer\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nThis app summarizes text into 3 key sentences.\")\n",
    "    print(\"You can either:\")\n",
    "    print(\"1. Enter text directly\")\n",
    "    print(\"2. Provide a URL to a news article or blog post\")\n",
    "    print(\"3. Use the sample text provided\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"-\" * 40)\n",
    "        print(\"Choose an option:\")\n",
    "        print(\"1. Enter text manually\")\n",
    "        print(\"2. Enter URL\")\n",
    "        print(\"3. Use sample text\")\n",
    "        print(\"4. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nEnter your choice (1-4): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            print(\"\\nEnter your text (press Enter twice to finish):\")\n",
    "            lines = []\n",
    "            while True:\n",
    "                line = input()\n",
    "                if line == '' and lines and lines[-1] == '':\n",
    "                    break\n",
    "                lines.append(line)\n",
    "            text = '\\n'.join(lines[:-1])  # Remove the last empty line\n",
    "            \n",
    "            if not text.strip():\n",
    "                print(\"No text entered. Please try again.\")\n",
    "                continue\n",
    "                \n",
    "            summary = summarizer.summarize(text)\n",
    "            print(\"\\n\" + \"=\" * 40)\n",
    "            print(\"SUMMARY:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(summary)\n",
    "            \n",
    "        elif choice == '2':\n",
    "            url = input(\"\\nEnter the URL: \").strip()\n",
    "            if not url:\n",
    "                print(\"No URL entered. Please try again.\")\n",
    "                continue\n",
    "                \n",
    "            print(\"Processing URL... This may take a moment.\")\n",
    "            summary = summarizer.summarize_from_url(url)\n",
    "            print(\"\\n\" + \"=\" * 40)\n",
    "            print(\"SUMMARY:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(summary)\n",
    "            \n",
    "        elif choice == '3':\n",
    "            # Sample text for demonstration\n",
    "            sample_text = \"\"\"\n",
    "            Artificial intelligence is transforming the way we live and work. \n",
    "            Machine learning algorithms can now recognize patterns in data that humans would miss. \n",
    "            Natural language processing allows computers to understand and generate human language. \n",
    "            AI systems are being used in healthcare to diagnose diseases more accurately. \n",
    "            In transportation, self-driving cars are becoming a reality. \n",
    "            Businesses use AI for customer service, fraud detection, and supply chain optimization. \n",
    "            However, there are also concerns about job displacement and ethical implications. \n",
    "            Researchers are working on making AI systems more transparent and fair. \n",
    "            The future of AI holds both great promise and significant challenges.\n",
    "            \"\"\"\n",
    "            \n",
    "            print(\"\\nUsing sample text about Artificial Intelligence...\")\n",
    "            summary = summarizer.summarize(sample_text)\n",
    "            print(\"\\n\" + \"=\" * 40)\n",
    "            print(\"ORIGINAL TEXT:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(sample_text)\n",
    "            print(\"\\n\" + \"=\" * 40)\n",
    "            print(\"SUMMARY:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(summary)\n",
    "            \n",
    "        elif choice == '4':\n",
    "            print(\"Thank you for using the Text Summarizer!\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, 3, or 4.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5273bce-c231-493e-909a-54bea48eecff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
